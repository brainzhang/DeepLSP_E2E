import os
import sys
import importlib
import importlib.util
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
import copy
import logging
from typing import Dict, Any, List, Tuple, Optional
from pathlib import Path

# pyright: reportCallIssue=false

def calculate_pruning_metrics(model: nn.Module, input_size: Tuple[int, int, int, int] = (1, 3, 224, 224)) -> Dict[str, Any]:
    """
    Calculate metrics for a pruned model.
    
    Args:
        model: Pruned PyTorch model
        input_size: Input tensor size (batch_size, channels, height, width)
        
    Returns:
        Dictionary with metrics (original and pruned params, FLOPs, reduction percentages)
    """
    logging.info("ğŸ“Š Calculating pruning metrics...")
    metrics = {}
    device = next(model.parameters()).device
    
    # Try to import FLOPs calculation libraries
    thop_available = False
    fvcore_available = False
    thop_module = None  # Initialize to avoid unbound errors
    
    try:
        import thop as thop_module
        thop_available = True
        logging.info("âœ… Using thop for FLOPs calculation")
    except ImportError:
        logging.warning("âš ï¸ thop not found, trying alternative FLOPs calculators")
    
    if not thop_available:
        try:
            from fvcore.nn import FlopCountAnalysis
            fvcore_available = True
            logging.info("âœ… Using fvcore for FLOPs calculation")
        except ImportError:
            logging.warning("âš ï¸ fvcore not found, will try custom FLOPs calculators")
    
    # Try custom metrics module as last resort
    metrics_module = None
    if not thop_available and not fvcore_available:
        try:
            import sys
            import importlib.util
            
            # Try to find metrics.py in utils directory or other common locations
            spec = importlib.util.find_spec("utils.metrics")
            if spec is None:
                for path in sys.path:
                    try:
                        metrics_path = os.path.join(path, "utils", "metrics.py")
                        if os.path.exists(metrics_path):
                            spec = importlib.util.spec_from_file_location("metrics", metrics_path)
                            break
                    except Exception:
                        continue
            
            if spec is not None and spec.loader is not None:
                metrics_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(metrics_module)
                logging.info("âœ… Using custom metrics module for calculations")
        except Exception as e:
            logging.error(f"âŒ Error loading custom metrics module: {e}")
            metrics_module = None
    
    # Create a copy of the unpruned model by restoring original weights
    original_model = copy.deepcopy(model)
    
    # Check if model has pruning masks applied
    has_pruning_masks = False
    for module in original_model.modules():
        if hasattr(module, 'weight_orig') and hasattr(module, 'weight_mask'):
            has_pruning_masks = True
            # Restore original weights (remove mask effect)
            if isinstance(module.weight_orig, torch.Tensor):
                with torch.no_grad():
                    if hasattr(module, 'weight') and module.weight is not None:
                        module.weight.data.copy_(module.weight_orig.data)
            # Remove pruning
            prune.remove(module, 'weight')
    
    # æ£€æµ‹é›¶æƒé‡å‰ªæ - å³ä½¿æ²¡æœ‰ä½¿ç”¨æ©ç ï¼Œä¹Ÿå¯èƒ½é€šè¿‡å°†æ•´ä¸ªé€šé“ç½®é›¶æ¥è¿›è¡Œå‰ªæ
    if not has_pruning_masks:
        logging.warning("âš ï¸ No pruning masks detected. Checking for zero-weight channels...")
        
        # è®¡ç®—æ¯ä¸ªå·ç§¯å±‚ä¸­çš„é›¶é€šé“æ¯”ä¾‹
        zero_channel_count = 0
        total_channel_count = 0
        
        for name, module in model.named_modules():
            if isinstance(module, nn.Conv2d):
                weight = module.weight.data
                out_channels = weight.shape[0]
                
                # æ£€æŸ¥æ¯ä¸ªè¾“å‡ºé€šé“æ˜¯å¦å…¨ä¸ºé›¶
                for i in range(out_channels):
                    channel_weights = weight[i]
                    if torch.sum(torch.abs(channel_weights)) == 0:
                        zero_channel_count += 1
                
                total_channel_count += out_channels
        
        # å¦‚æœæœ‰æ˜¾è‘—æ•°é‡çš„é›¶é€šé“ï¼Œåˆ™è®¤ä¸ºå·²åº”ç”¨äº†é€šé“å‰ªæ
        zero_channel_ratio = zero_channel_count / max(1, total_channel_count)
        if zero_channel_ratio > 0.01:  # è¶…è¿‡1%çš„é€šé“ä¸ºé›¶
            has_pruning_masks = True  # å°†é›¶é€šé“ä¹Ÿè§†ä¸ºä¸€ç§å‰ªæ
            logging.info(f"ğŸ“Š æ£€æµ‹åˆ°é›¶é€šé“å‰ªæ: {zero_channel_count}/{total_channel_count} é€šé“ ({zero_channel_ratio:.2%})")
        else:
            logging.warning("âš ï¸ æœªæ£€æµ‹åˆ°æ˜¾è‘—çš„å‰ªææ•ˆæœï¼Œæ¨¡å‹å¯èƒ½æœªè¢«å‰ªæ")
    
    if not has_pruning_masks:
        logging.warning("âš ï¸ æ— æ³•æ£€æµ‹åˆ°ä»»ä½•å‰ªææ ‡è®°æˆ–é›¶æƒé‡é€šé“ã€‚ä½¿ç”¨åŸå§‹å‚æ•°è¿›è¡Œåº¦é‡è®¡ç®—ã€‚")
    
    # ç¡®ä¿è®¡ç®—å®é™…çš„éé›¶å‚æ•°æ•°é‡
    pruned_params_total = sum(p.numel() for p in model.parameters() if p.requires_grad)
    original_params = sum(p.numel() for p in original_model.parameters() if p.requires_grad)
    
    # è®¡ç®—å‰ªææ¨¡å‹ä¸­çš„éé›¶å‚æ•°
    nonzero_params = 0
    for name, param in model.named_parameters():
        if param.requires_grad:
            nonzero_params += torch.count_nonzero(param).item()
    
    metrics['original_params'] = original_params
    metrics['pruned_params'] = nonzero_params
    metrics['param_reduction'] = 100.0 * (1.0 - nonzero_params / original_params) if original_params > 0 else 0
    
    # Calculate FLOPs using available methods
    if thop_available and thop_module is not None:
        # Use thop for FLOPs calculation
        try:
            # Create correctly sized input tensors
            dummy_input = torch.randn(input_size).to(device)
            
            # Calculate FLOPs for original model
            original_model.eval()
            temp = thop_module.profile(original_model, inputs=(dummy_input,), verbose=False)
            # thop sometimes returns 2 or 3 values, handle both cases
            if isinstance(temp, tuple) and len(temp) >= 2:
                macs = temp[0]
                original_flops = macs * 2  # Convert MACs to FLOPs
            
                # Calculate FLOPs for pruned model
                model.eval() 
                temp = thop_module.profile(model, inputs=(dummy_input,), verbose=False)
                macs = temp[0]
                pruned_flops = macs * 2
                
                metrics['original_flops'] = original_flops
                metrics['pruned_flops'] = pruned_flops
                metrics['flops_reduction'] = 100.0 * (1.0 - pruned_flops / original_flops) if original_flops > 0 else 0
                
                logging.info(f"ğŸ“Š Original model: Parameters {original_params:,}, FLOPs {original_flops/1e6:.2f}M")
                logging.info(f"ğŸ“Š Pruned model: Parameters {nonzero_params:,}, FLOPs {pruned_flops/1e6:.2f}M")
                logging.info(f"ğŸ“Š Reduction: Parameters {metrics['param_reduction']:.2f}%, FLOPs {metrics['flops_reduction']:.2f}%")
            else:
                logging.warning("âš ï¸ Unexpected output format from thop.profile")
                thop_available = False
        except Exception as e:
            logging.error(f"âŒ Error calculating FLOPs with thop: {e}")
            thop_available = False
            
    elif fvcore_available:
        # Use fvcore for FLOPs calculation
        try:
            from fvcore.nn import FlopCountAnalysis
            dummy_input = torch.randn(input_size).to(device)
            
            # Calculate FLOPs for original model
            original_model.eval()
            flops_analysis = FlopCountAnalysis(original_model, dummy_input)
            original_flops = flops_analysis.total()
            
            # Calculate FLOPs for pruned model
            model.eval()
            flops_analysis = FlopCountAnalysis(model, dummy_input)
            pruned_flops = flops_analysis.total()
            
            metrics['original_flops'] = original_flops
            metrics['pruned_flops'] = pruned_flops
            metrics['flops_reduction'] = 100.0 * (1.0 - pruned_flops / original_flops) if original_flops > 0 else 0
            
            logging.info(f"ğŸ“Š Original model: Parameters {original_params:,}, FLOPs {original_flops/1e6:.2f}M")
            logging.info(f"ğŸ“Š Pruned model: Parameters {nonzero_params:,}, FLOPs {pruned_flops/1e6:.2f}M")
            logging.info(f"ğŸ“Š Reduction: Parameters {metrics['param_reduction']:.2f}%, FLOPs {metrics['flops_reduction']:.2f}%")
        except Exception as e:
            logging.error(f"âŒ Error calculating FLOPs with fvcore: {e}")
            fvcore_available = False
            
    elif metrics_module is not None and hasattr(metrics_module, 'calculate_flops'):
        # Use custom metrics module
        try:
            original_flops = metrics_module.calculate_flops(original_model, input_size)
            pruned_flops = metrics_module.calculate_flops(model, input_size)
            
            metrics['original_flops'] = original_flops
            metrics['pruned_flops'] = pruned_flops
            metrics['flops_reduction'] = 100.0 * (1.0 - pruned_flops / original_flops) if original_flops > 0 else 0
            
            logging.info(f"ğŸ“Š Original model: Parameters {original_params:,}, FLOPs {original_flops/1e6:.2f}M")
            logging.info(f"ğŸ“Š Pruned model: Parameters {nonzero_params:,}, FLOPs {pruned_flops/1e6:.2f}M")
            logging.info(f"ğŸ“Š Reduction: Parameters {metrics['param_reduction']:.2f}%, FLOPs {metrics['flops_reduction']:.2f}%")
        except Exception as e:
            logging.error(f"âŒ Error calculating FLOPs with custom metrics: {e}")
    
    # å¦‚æœæ‰€æœ‰FLOPè®¡ç®—æ–¹æ³•éƒ½å¤±è´¥ï¼Œåˆ™è‡ªè¡Œè®¡ç®—
    if 'flops_reduction' not in metrics:
        # æ‰‹åŠ¨è®¡ç®—FLOP
        logging.info("ğŸ“Š ä½¿ç”¨æ‰‹åŠ¨æ–¹æ³•è®¡ç®—FLOPS...")
        
        # åˆå§‹åŒ–è®¡æ•°å™¨
        original_flops_count = 0
        pruned_flops_count = 0
        
        # éå†å¹¶è®¡ç®—æ¯å±‚çš„FLOPS
        for (name_orig, module_orig), (name_pruned, module_pruned) in zip(
            original_model.named_modules(), model.named_modules()):
            
            # åªå¤„ç†è®¡ç®—å¯†é›†å‹å±‚
            if isinstance(module_orig, nn.Conv2d) and isinstance(module_pruned, nn.Conv2d):
                # è·å–å‚æ•°
                k_h, k_w = module_orig.kernel_size if isinstance(module_orig.kernel_size, tuple) else (module_orig.kernel_size, module_orig.kernel_size)
                in_c_orig = module_orig.in_channels
                out_c_orig = module_orig.out_channels
                in_c_pruned = module_pruned.in_channels
                out_c_pruned = module_pruned.out_channels
                groups_orig = module_orig.groups
                groups_pruned = module_pruned.groups
                
                # è®¡ç®—ç‰¹å¾å›¾å°ºå¯¸ (å‡è®¾è¾“å…¥æ˜¯input_sizeæŒ‡å®šçš„å¤§å°)
                stride = module_orig.stride[0] if isinstance(module_orig.stride, tuple) else module_orig.stride
                padding = module_orig.padding[0] if isinstance(module_orig.padding, tuple) else module_orig.padding
                dilation = module_orig.dilation[0] if isinstance(module_orig.dilation, tuple) else module_orig.dilation
                
                # è®¡ç®—è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸
                h_in, w_in = input_size[2], input_size[3]
                h_out = (h_in + 2 * int(padding) - int(dilation) * (k_h - 1) - 1) // int(stride) + 1
                w_out = (w_in + 2 * int(padding) - int(dilation) * (k_w - 1) - 1) // int(stride) + 1
                
                # è®¡ç®—åŸå§‹FLOPS: 2 * H_out * W_out * K_h * K_w * C_in * C_out / groups
                original_layer_flops = 2 * h_out * w_out * k_h * k_w * in_c_orig * out_c_orig // groups_orig
                original_flops_count += original_layer_flops
                
                # å¦‚æœç»“æ„çœŸçš„å˜äº† (é€šé“æ•°å‡å°‘)
                if in_c_pruned < in_c_orig or out_c_pruned < out_c_orig:
                    pruned_layer_flops = 2 * h_out * w_out * k_h * k_w * in_c_pruned * out_c_pruned // groups_pruned
                    pruned_flops_count += pruned_layer_flops
                    logging.info(f"ğŸ“Š å±‚{name_orig}: é€šé“ä»{in_c_orig}x{out_c_orig}å‡å°‘åˆ°{in_c_pruned}x{out_c_pruned}, FLOPSå‡å°‘: {100*(1-pruned_layer_flops/original_layer_flops):.2f}%")
                else:
                    # ç»“æ„æ²¡å˜ï¼Œä½†å¯èƒ½æœ‰å¾ˆå¤šé›¶æƒé‡
                    nonzero_weights = torch.count_nonzero(module_pruned.weight).item()
                    total_weights = module_pruned.weight.numel()
                    nonzero_ratio = nonzero_weights / total_weights if total_weights > 0 else 1.0
                    
                    pruned_layer_flops = original_layer_flops * nonzero_ratio
                    pruned_flops_count += pruned_layer_flops
                    logging.info(f"ğŸ“Š å±‚{name_orig}: æƒé‡ç¨€ç–åº¦: {1-nonzero_ratio:.2f}, FLOPSå‡å°‘: {100*(1-nonzero_ratio):.2f}%")
            
            elif isinstance(module_orig, nn.Linear) and isinstance(module_pruned, nn.Linear):
                # çº¿æ€§å±‚FLOPS: 2 * in_features * out_features
                original_layer_flops = 2 * module_orig.in_features * module_orig.out_features
                original_flops_count += original_layer_flops
                
                if module_pruned.in_features < module_orig.in_features or module_pruned.out_features < module_orig.out_features:
                    pruned_layer_flops = 2 * module_pruned.in_features * module_pruned.out_features
                    pruned_flops_count += pruned_layer_flops
                else:
                    nonzero_weights = torch.count_nonzero(module_pruned.weight).item()
                    total_weights = module_pruned.weight.numel()
                    nonzero_ratio = nonzero_weights / total_weights if total_weights > 0 else 1.0
                    
                    pruned_layer_flops = original_layer_flops * nonzero_ratio
                    pruned_flops_count += pruned_layer_flops
        
        # æ›´æ–°åº¦é‡ç»“æœ
        if original_flops_count > 0:
            metrics['original_flops'] = original_flops_count
            metrics['pruned_flops'] = pruned_flops_count
            flops_reduction = 100.0 * (1.0 - pruned_flops_count / original_flops_count)
            metrics['flops_reduction'] = flops_reduction
            
            logging.info(f"ğŸ“Š æ‰‹åŠ¨è®¡ç®— - åŸå§‹FLOPS: {original_flops_count/1e6:.2f}M")
            logging.info(f"ğŸ“Š æ‰‹åŠ¨è®¡ç®— - å‰ªæåFLOPS: {pruned_flops_count/1e6:.2f}M")
            logging.info(f"ğŸ“Š æ‰‹åŠ¨è®¡ç®— - FLOPSå‡å°‘: {flops_reduction:.2f}%")
        else:
            # æœ€åçš„åŠæ³•ï¼Œä½¿ç”¨å‚æ•°å‡å°‘æ¯”ä¾‹ä½œä¸ºä¼°è®¡
            param_reduction_ratio = metrics['param_reduction'] / 100.0
            metrics['flops_reduction'] = metrics['param_reduction']  # æˆ–è€…æ›´ä¿å®ˆåœ°åŸºäºå‚æ•°ç¨€ç–åº¦ä¼°è®¡
            
            logging.warning("âš ï¸ æ— æ³•ç›´æ¥è®¡ç®—FLOPSï¼Œä½¿ç”¨å‚æ•°å‡å°‘æ¯”ä¾‹ä½œä¸ºä¼°è®¡å€¼")
            logging.info(f"ğŸ“Š ä¼°è®¡FLOPSå‡å°‘: {metrics['flops_reduction']:.2f}%")
    
    return metrics

def get_model_pruning_ratio(model: nn.Module) -> float:
    """
    Calculate the overall pruning ratio of a model.
    
    Args:
        model: PyTorch model with pruning applied
        
    Returns:
        Pruning ratio (0.0 - 1.0)
    """
    total_weights = 0
    zero_weights = 0
    
    for name, module in model.named_modules():
        if isinstance(module, (nn.Conv2d, nn.Linear)):
            weight = module.weight.data
            total_weights += weight.numel()
            zero_weights += (weight == 0).sum().item()
    
    return zero_weights / total_weights if total_weights > 0 else 0.0 